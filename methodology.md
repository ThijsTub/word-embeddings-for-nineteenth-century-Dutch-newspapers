  I trained word embeddings based on newspaper data dating from 1815 until 1879 available in the public newspaper database of Delpher.  After downloading and unzipping the files, I collected the metadata in an Excel file. The metadata was used to filter the newspapers for date, language, and publication type (i.e., article, advertisement, or family announcement). Before modelling the word embeddings, the data was pre-filtered and pre-processed. I pre-processed the data in chunks of one year, and only those texts that were labelled as ‘Dutch’ and ‘article’. Pre-processing consisted of tokenising the text, segmenting the text into sentences, making all tokens lowercase, eliminating tokens up to three and longer than fifteen characters, eliminating stop words, and eliminating sentences that contained more than 30 percent misspelt words, which were identified by using a list of historic Dutch words.  The spelling check was especially important as the historic data I used was created using OCR and therefore contained many misspelled words. Using the pre-processed data, I created ten different sets of word embeddings for ten different timeframes using the Word2Vec implementation of Gensim.  Word2Vec was run with default settings, except for dimensionality, which was set to 300. The timeframes were chosen based on the amount of newspaper data available, which steadily increases over the nineteenth century, and the aim to create a somewhat fine-grained depiction of temporal semantic change of words of interest. Therefore, I split the period preceding the year the potato blight first occurred (1845) into three timeframes of ten years and the period from 1845 onwards into seven timeframes of five years. While for none of the timeframes the amount of tokens reached the desired minimum of 100 million, I believe that the following application of the word embeddings has proven their useful for the heuristic ends of this study. 
  

